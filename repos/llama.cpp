Description: llama.cpp is an open-source project that provides a C/C++ implementation of Metaâ€™s LLaMA (Large Language Model Meta AI) models.
Home Page: https://github.com/ggml-org/llama.cpp
Programs: llama-batched,llama-batched-bench,llama-bench,llama-cli,llama-embedding,llama-eval-callback,llama-finetune,llama-gemma3-cli,llama-gen-docs,llama-gguf,llama-gguf-hash,llama-gguf-split,llama-gritlm,llama-imatrix,llama-llava-cli,llama-lookahead,llama-lookup,llama-lookup-create,llama-lookup-merge,llama-lookup-stats,llama-minicpmv-cli,llama-mtmd-cli,llama-parallel,llama-passkey,llama-perplexity,llama-quantize,llama-qwen2vl-cli,llama-retrieval,llama-run,llama-save-load-state,llama-server,llama-simple,llama-simple-chat,llama-speculative,llama-speculative-simple,llama-tokenize,llama-tts
version("full-cuda-b5627", uri="docker://tuftsttsrt/llama.cpp:full-cuda-b5627")
version("full-cuda-b5590", uri="docker://tuftsttsrt/llama.cpp:full-cuda-b5590")
version("full-cuda-b5590", uri="docker://tuftsttsrt/llama.cpp:full-cuda-b5590")
